# üîß Soluci√≥n: Timeout en Termux

## Cambios Aplicados

1. ‚úÖ **Timeout aumentado a 5 minutos** (300 segundos) en cliente Termux
2. ‚úÖ **Prompts simplificados** para que Ollama responda m√°s r√°pido
3. ‚úÖ **Integraci√≥n inteligente solo para archivos existentes** (archivos nuevos usan overwrite autom√°tico)

## Actualizar C√≥digo en Termux

```bash
git pull
```

## Probar de Nuevo

```bash
# Probar con archivo nuevo (m√°s r√°pido, sin integraci√≥n)
cursor query "Crea una funci√≥n que sume dos n√∫meros" --write suma.py
```

## Si Sigue Siendo Muy Lento

### Opci√≥n 1: Probar Sin Integraci√≥n Inteligente

Para archivos nuevos, ya no usa integraci√≥n (m√°s r√°pido). Para archivos existentes, puedes forzar overwrite:

```bash
cursor query "Reemplaza todo con funci√≥n suma" --write suma.py
```

### Opci√≥n 2: Usar Modelo M√°s R√°pido

```powershell
# En ordenador
.\cambiar_modelo.ps1 mistral
# Reiniciar servidor
```

### Opci√≥n 3: Ver Logs del Servidor

En la terminal donde corre el servidor, deber√≠as ver:
- Cu√°ndo recibe la petici√≥n
- Cu√°ndo llama a Ollama  
- Cu√°ndo termina

Si no ves actividad despu√©s de recibir la petici√≥n, Ollama puede estar bloqueado.

### Opci√≥n 4: Probar Consulta Simple Primero

```bash
# Probar sin escribir archivo (m√°s r√°pido)
cursor query "Hola, ¬øfuncionas?"

# Si esto funciona r√°pido, el problema es la generaci√≥n de c√≥digo
```

## Verificar Ollama en Servidor

```powershell
# En ordenador, probar Ollama directamente
ollama run codellama "Escribe funci√≥n Python suma"

# Si esto tarda m√°s de 2 minutos, Ollama es el problema
```

## Notas

- ‚úÖ Timeout aumentado a 5 minutos
- ‚úÖ Prompts simplificados (m√°s r√°pidos)
- ‚úÖ Archivos nuevos no usan integraci√≥n (m√°s r√°pido)
- ‚ö†Ô∏è Ollama puede ser lento, especialmente primera consulta
- ‚ö†Ô∏è Es normal que tarde 1-3 minutos con Ollama
