# üîç Verificar que el Servidor Est√° Funcionando

## Problema: Timeout

El error de timeout puede ser porque:
1. El servidor no est√° corriendo
2. Ollama est√° tardando mucho (normal)
3. Problema de conexi√≥n

## Verificaci√≥n Paso a Paso

### 1. Verificar que el Servidor Est√° Corriendo

**En tu ordenador (PowerShell):**
```powershell
# Ver procesos Python
Get-Process | Where-Object {$_.ProcessName -like "*python*"}

# Verificar puerto 8000
Test-NetConnection -ComputerName localhost -Port 8000
```

**Si el servidor NO est√° corriendo:**
```powershell
# Iniciar servidor
python start_server.py

# Deber√≠as ver:
# INFO:     Started server process
# INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 2. Verificar que Ollama Est√° Corriendo

```powershell
# Ver modelos instalados
ollama list

# Probar Ollama directamente
ollama run codellama "Escribe una funci√≥n Python simple que sume dos n√∫meros"
```

**Si Ollama no responde:**
```powershell
# Iniciar Ollama manualmente (en otra terminal)
ollama serve

# Dejar corriendo
```

### 3. Verificar Configuraci√≥n

```powershell
# Verificar .env
Get-Content .env | Select-String -Pattern "AI_PROVIDER|OLLAMA"

# Deber√≠a mostrar:
# AI_PROVIDER=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=codellama
```

### 4. Probar Conexi√≥n B√°sica

**Desde Termux:**
```bash
# Probar conexi√≥n b√°sica (sin IA)
curl $CURSOR_SERVER_URL/health

# Deber√≠as ver: {"status":"ok"}
```

### 5. Probar con Timeout Aumentado

**Actualiza el c√≥digo en Termux:**
```bash
git pull
```

**Luego prueba:**
```bash
# Ahora con timeout de 120 segundos
cursor query "Crea una funci√≥n que sume dos n√∫meros" --write suma.py
```

## Si Sigue Fallando

### Ver Logs del Servidor

En la terminal donde corre el servidor, deber√≠as ver logs. Si hay errores, aparecer√°n ah√≠.

### Probar Ollama Directamente

```powershell
# En tu ordenador
ollama run codellama "Escribe una funci√≥n Python que sume dos n√∫meros"
```

Si esto funciona, Ollama est√° bien. El problema puede ser:
- El servidor no est√° usando Ollama correctamente
- Timeout a√∫n muy corto
- Problema de red

### Usar Modelo M√°s R√°pido

```powershell
# Cambiar a mistral (m√°s r√°pido)
.\cambiar_modelo.ps1 mistral

# Reiniciar servidor
```

## Soluci√≥n Temporal: Aumentar Timeout Manualmente

Si necesitas m√°s tiempo, edita `termux/cursor_client.py`:

```python
# L√≠nea ~44, cambiar:
timeout_value = kwargs.pop('timeout', 300)  # 5 minutos
```

## Notas Importantes

- ‚úÖ Timeouts aumentados a 120s (cliente) y 180s (servidor)
- ‚ö†Ô∏è Primera consulta con Ollama puede tardar 1-2 minutos
- ‚ö†Ô∏è Consultas siguientes ser√°n m√°s r√°pidas
- ‚ö†Ô∏è Es normal que Ollama sea m√°s lento que APIs pagas
