# Configuración del Servidor Bridge
# Copia este archivo a .env y ajusta los valores según tu configuración

# URL del servidor bridge (en tu computadora)
CURSOR_SERVER_URL=http://localhost:8000

# Token de autenticación (genera uno seguro)
API_TOKEN=change-me-in-production

# Puerto del servidor
PORT=8000

# Ruta del workspace de Cursor
CURSOR_WORKSPACE_PATH=.

# Para acceso remoto (ngrok/tailscale), actualiza CURSOR_SERVER_URL con la URL pública
# Ejemplo con ngrok: CURSOR_SERVER_URL=https://abc123.ngrok.io

# Configuración de IA (elige una opción)
# Opción 1: OpenAI
AI_PROVIDER=openai
OPENAI_API_KEY=sk-tu-api-key-aqui
OPENAI_MODEL=gpt-4

# Opción 2: Anthropic Claude
# AI_PROVIDER=anthropic
# ANTHROPIC_API_KEY=tu-api-key-aqui
# ANTHROPIC_MODEL=claude-3-opus-20240229

# Opción 3: Ollama (modelo local)
# AI_PROVIDER=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama2

# Opción 4: LM Studio (modelo local)
# AI_PROVIDER=lmstudio
# LMSTUDIO_BASE_URL=http://localhost:1234
# LMSTUDIO_MODEL=local-model
